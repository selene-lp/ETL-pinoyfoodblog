{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ETL - PinoyFoodBlog\n",
    "\n",
    "This ETL project for PinoyFoodBlog demonstrates an ETL process with <b>Medallion Architecture</b>, <b>Web Scraping</b>, <b>Data Modeling</b>, <b>Pandas</b>, <b>Python</b>, <b>SQL</b>, and <b>Jupyter Notebook</b>. The project includes three stages: Bronze, Silver, and Gold, each with specific data processing and storage methods.\n",
    "\n",
    "- Bronze Stage:\n",
    "\n",
    "    - <b>File:</b> `extract.py`\n",
    "    - <b>Process:</b> Web scraping is performed asynchronously using `playwright` and `asyncio`, with an object-oriented structure provided by `dataclasses`. The raw data is saved in `datasets/bronze` for initial processing.\n",
    "\n",
    "- Silver Stage:\n",
    "\n",
    "    - <b>File:</b> `transform.ipynb`\n",
    "    - <b>Process:</b> Data is cleaned and normalized in `Jupyter` using `pandas`, with spelling corrections by `thefuzz` and unit standardization by `pint`. The structured data is saved in `datasets/silver` as a cleaned dataset and `pinoyfoodblog.db` file.\n",
    "\n",
    "- Gold Stage:\n",
    "\n",
    "    - <b>File:</b> `load.ipynb`\n",
    "    - <b>Process:</b> Using `sqlalchemy`, the analytics-ready data is loaded from the Silver database. Aggregated insights are saved as a Parquet file in `datasets/gold`, providing analytics on cooking times, nutritional content, and servings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation Process\n",
    "\n",
    "You need to install Jupyter Notebook or VS Code jupyter extension to view or run the .ipynb files.\n",
    "\n",
    "For the pip installation packages used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install pandas thefuzz pint sqlalchemy playwright\n",
    "pip install playwright"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Output\n",
    "\n",
    "From extraction, It will saved a .json file with a filename of pinoyfoodblog.json. and will be transformed and load using the .ipynb files.\n",
    "\n",
    "For your references, here are the expected outputs from raw data to analytics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    Raw data from extraction<br>\n",
    "    <img src=\"Images/json-structure.png\" alt=\"json-structure\" width=\"65%\"/><br><br>\n",
    "    Normalized database structure<br>\n",
    "    <img src=\"Images/ERD.png\" alt=\"ERD\" width=\"80%\"/><br><br>\n",
    "    Analytics<br>\n",
    "    <img src=\"Images/analytics.png\" alt=\"ERD\" width=\"100%\"/>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selene-de-python-3-11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
